{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chensar6/APS360/blob/main/Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls -a \"/content/drive/MyDrive/APS360_Images\""
      ],
      "metadata": {
        "id": "EcOPYiUcHi9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34f844c-33ab-4ef3-c09c-9e1bceb7272c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\"Ahmed's Colab.ipynb\"\t\t Final_Data_Acc       Test.ipynb\n",
            " bounding_box_processing.ipynb\t .ipynb_checkpoints\n",
            " Final_Data\t\t\t Raw_Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q9AJCSFSHSPv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import gc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "----\n",
        "The following is for rotating and saving images"
      ],
      "metadata": {
        "id": "kCdokpdorNrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to rotate and resize the image\n",
        "# will want to save these, I still need to look into saving- Narender\n",
        "def rotateResizeImage(img):\n",
        "  img1 = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "  img2 = cv2.rotate(img, cv2.ROTATE_180)\n",
        "  img3 = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "\n",
        "  rotated_images = [img, img1, img2, img3]\n",
        "  resized_images = []\n",
        "\n",
        "  for r_img in rotated_images:\n",
        "    # Get the dimensions of the original image\n",
        "    height, width, _ = r_img.shape\n",
        "\n",
        "    # Determine the padding required to make the image square\n",
        "    diff = abs(height - width)\n",
        "    padding = diff // 2\n",
        "\n",
        "    # Pad the image with zeros\n",
        "    if height > width:\n",
        "        r_img = cv2.copyMakeBorder(r_img, 0, 0, padding, padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "    else:\n",
        "        r_img = cv2.copyMakeBorder(r_img, padding, padding, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "    # Resize the image to 256x256\n",
        "    resized = cv2.resize(r_img, (256, 256))\n",
        "    resized_images.append(resized)\n",
        "\n",
        "  return resized_images"
      ],
      "metadata": {
        "id": "AMgwWXRfjeno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##this is what actually saves it\n",
        "from google.colab.patches import cv2_imshow #to display\n",
        "\n",
        "# makes our life easier by automating\n",
        "input_folders = [\"y_raw\"]\n",
        "output_folders = [\"y\"]\n",
        "\n",
        "for i in range(len(input_folders)):\n",
        "  print(\"\\nFOLDER \" + str(i + 1) + \" OUT OF 3...\\n\")\n",
        "  \n",
        "  #change the following to work with any input folder and output folder\n",
        "  input_path =\"/content/drive/MyDrive/APS360_Images/Raw_Data/\" + input_folders[i] #this is where the images are coming from \n",
        "  output_path= \"/content/drive/MyDrive/APS360_Images/Final_Data_Acc/\" + output_folders[i] #this is where the roated images are going\n",
        "\n",
        "  #if changing the paths, make sure to change the following line as well. \n",
        "  i_images = [(os.path.join(input_path, f), f) for f in os.listdir(input_path) if (f.endswith('.jpg'))]\n",
        "  o_images = [(os.path.join(output_path, f), f) for f in os.listdir(output_path) if (f.endswith('.jpg'))]\n",
        "\n",
        "  import random\n",
        "  k = random.randint(0, len(i_images))\n",
        "\n",
        "  i_img = cv2.imread(i_images[k][0])\n",
        "  i_img = cv2.cvtColor(i_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  plt.imshow(i_img, cmap=\"hot\")\n",
        "  plt.show()\n",
        "\n",
        "  print(i_images[k][1])\n",
        "\n",
        "  z = int()\n",
        "  for i, (f1, f2) in enumerate(o_images):\n",
        "    if (i_images[k][1].split(\".\")[0] in f2) and (\"Rotated0\" in f2):\n",
        "      z = i\n",
        "      break\n",
        "  \n",
        "  print(o_images[z][1])\n",
        "  o_img = cv2.imread(o_images[z][0])\n",
        "  o_img = cv2.cvtColor(o_img, cv2.COLOR_BGR2GRAY)\n",
        "  plt.imshow(o_img, cmap=\"hot\")\n",
        "  plt.show()\n",
        "  \"\"\"\n",
        "  #this sets the output dir as current dir\n",
        "  os.chdir(output_path)\n",
        "\n",
        "  numOfImages= len(images)\n",
        "\n",
        "  # Clean memory\n",
        "  gc.collect()\n",
        "\n",
        "  for i in range(numOfImages):\n",
        "    image = cv2.imread(images[i][0])\n",
        "    imageRotated=rotateResizeImage(image)\n",
        "    \n",
        "    #save all the images with edited names, including the original\n",
        "    cv2.imwrite( images[i][1].replace('.jpg', '_Rotated0.jpg'), cv2.cvtColor(imageRotated[0], cv2.COLOR_BGR2RGB))\n",
        "    cv2.imwrite( images[i][1].replace('.jpg', '_Rotated90.jpg'), cv2.cvtColor(imageRotated[1], cv2.COLOR_BGR2RGB))\n",
        "    cv2.imwrite( images[i][1].replace('.jpg', '_Rotated180.jpg'), cv2.cvtColor(imageRotated[2], cv2.COLOR_BGR2RGB))\n",
        "    cv2.imwrite( images[i][1].replace('.jpg', '_Rotated270.jpg'), cv2.cvtColor(imageRotated[3], cv2.COLOR_BGR2RGB))\n",
        "    print(\"Done processing image {0}/1152...\".format(i+1))\"\"\""
      ],
      "metadata": {
        "id": "AK0b9d1NhA-8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "0eea0a98-2a80-4f44-9f70-22edb8e4087c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FOLDER 1 OUT OF 3...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C92_D2_P2.jpg\n",
            "C92_D2_P2_Rotated0.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00p166_U_i7K",
        "outputId": "eef5216f-7d6f-4d4a-c80e-9e916407e806"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "1A4SOkgEv36I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import truediv\n",
        "# Code to retrieve data and make DataLoaders\n",
        "# 0.8, 0.1, 0.1 split?\n",
        "\n",
        "# Define custom dataset class that inherits from torch Dataset in order to load data\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, bool_RGB=True, num_classes=46):\n",
        "        self.x_dir = os.path.join(root_dir, \"x_RGB\" if bool_RGB else \"x_gray\")\n",
        "        self.y_dir = os.path.join(root_dir, 'y')\n",
        "        \n",
        "        self.filenames = os.listdir(self.x_dir)\n",
        "        self.bool_RGB = bool_RGB\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        # Define transform to convert images to Tensors that can be fed to model directly\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_path = os.path.join(self.x_dir, self.filenames[idx])\n",
        "        y_path = os.path.join(self.y_dir, self.filenames[idx])\n",
        "\n",
        "        x = self.transform(Image.open(x_path).convert('RGB' if self.bool_RGB else \"L\")).to(torch.float32)\n",
        "\n",
        "        # Convert image to tensor, clip values to num_classes, \n",
        "        # then one-hot encode the labellings\n",
        "        # Then convert to NCHW format, then convert to float32\n",
        "        y = torch.from_numpy(np.array(Image.open(y_path).convert(\"L\")))\n",
        "        y = torch.clamp(y, max=self.num_classes-1)\n",
        "        y = F.one_hot(y.to(torch.int64), self.num_classes)\n",
        "        y = y.permute(2, 0, 1).to(torch.float32)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "\n",
        "# Define the dataset and separate training, val, test\n",
        "torch.manual_seed(1000)\n",
        "dataset = ImageDataset(\"/content/drive/MyDrive/APS360_Images/Final_Data_Acc/\", bool_RGB=True) # set to false if training on grayscale\n",
        "\n",
        "# Calculate the number of examples for each split\n",
        "num_train = int(len(dataset) * 0.8)\n",
        "num_val = int(len(dataset) * 0.1)\n",
        "num_test = len(dataset) - num_train - num_val\n",
        "\n",
        "# Split the dataset into three parts\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [num_train, num_val, num_test])\n",
        "\n",
        "\"\"\"\n",
        "# Create DataLoaders for each part\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\"\"\""
      ],
      "metadata": {
        "id": "kLhQUcT-RfOx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b82c8bd4-8a42-4bd4-9638-df2371d6df9a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Create DataLoaders for each part\\nbatch_size = 32\\n\\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "for (input, label) in train_dataloader:\n",
        "  print(input.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "t9BV01LD0SL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3beac8c3-5972-4e5e-8ee2-447339f5a8cf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4608\n",
            "torch.Size([32, 3, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, num_components):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # input size = 1024*1024\n",
        "        self.num_components = num_components\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        # Remove the last linear layer and replace it with a convolutional layer\n",
        "        self.encoder = nn.Sequential(*list(self.resnet.children())[:-1], nn.Conv2d(2048, 4096, kernel_size=1))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(4096, 2048, kernel_size=2, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(2048, 1024, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(1024, 512, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, 60, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(60, 55, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(55, 50, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(50, self.num_components, kernel_size=3, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forwardRGB(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "    \n",
        "    def forwardGray(self, x):\n",
        "        x = np.repeat(x[..., np.newaxis], 3, -1) # repeat the gray cahnnel for 3 channels. double check this\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9GLiJB-a_P8K"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel(model, train_data, valid_data, num_epochs=5, batch_size=64, learning_rate=1e-3, plot = True, model_forward=None):\n",
        "    # Move stuff to GPU\n",
        "    #  \n",
        "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # torch.cuda.empty_cache()\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    # model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss() # mean square error loss\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
        "    scaler = GradScaler()\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    train_loss_total, valid_loss_total = [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Clear ram to save from crashing\n",
        "        gc.collect()\n",
        "\n",
        "        for train_img, train_label in train_loader:\n",
        "\n",
        "            # train_img = train_img.to(device)\n",
        "            # train_label = train_label.to(device)\n",
        "\n",
        "            train_output = model_forward(train_img)\n",
        "\n",
        "            # Compute the loss\n",
        "            print(train_label.shape)\n",
        "            print(train_output.shape)\n",
        "            train_loss = criterion(train_output, train_label)\n",
        "\n",
        "            #train_img = train_img.view(-1, 1024*1024*3)\n",
        "            print(train_loss)\n",
        "            #train_loss.backward()\n",
        "            # Backward pass\n",
        "            scaler.scale(train_loss).backward()\n",
        "            \n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            \n",
        "            #optimizer.step()\n",
        "            #optimizer.zero_grad()\n",
        "\n",
        "            # Update the weights\n",
        "            scaler.step(optimizer)\n",
        "            \n",
        "            # Update the scaler for mixed precision training\n",
        "            scaler.update()\n",
        "        \n",
        "        for valid_img, valid_label in valid_loader:\n",
        "            valid_output = model_forward(valid_img)\n",
        "            valid_loss = criterion(valid_output, valid_label)\n",
        "\n",
        "        print('Epoch:{}, Train Loss:{:.4f}, Valid Loss:{:.4f}'.format(epoch+1, float(train_loss), float(valid_loss)))\n",
        "        train_loss_total.append(train_loss.cpu().detach().numpy())\n",
        "        valid_loss_total.append(valid_loss.cpu().detach().numpy())\n",
        "        \n",
        "        \n",
        "    if plot:\n",
        "        plt.title(\"Training/Validation loss\")\n",
        "        plt.plot(train_loss_total, label=\"Training Loss\")\n",
        "        plt.plot(valid_loss_total, label=\"Validation Loss\")\n",
        "        plt.xlabel(\"Iterations\")\n",
        "        plt.legend(loc='best')\n",
        "        plt.show()\n",
        "        \n",
        "        # plt.figure()\n",
        "        # plt.title(\"Training/Validation loss\")\n",
        "        # plt.plot(train_accs, label=\"Training Accuracy\")\n",
        "        # plt.plot(val_accs, label=\"Validation Accuracy\")\n",
        "        # plt.xlabel(\"Iterations\")\n",
        "        # plt.legend(loc='best')\n",
        "        # plt.show()\n",
        "         \n",
        "    # Save the model\n",
        "    torch.save(model.state_dict(), type(model).__name__ + \"lr{0}_bs{1}_ep{2}\".format(learning_rate, batch_size, num_epochs))\n",
        "\n",
        "    return train_loss_total, valid_loss_total"
      ],
      "metadata": {
        "id": "nb4Zb0_AVhg8"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "for img, label in train_loader:\n",
        "  print(label.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luvDPJE0D4Xu",
        "outputId": "1876d3e4-61b7-41b3-9a99-2dee9229d966"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 46, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear ram before defining model\n",
        "gc.collect()\n",
        "\n",
        "autoencoder = Autoencoder(num_components=46)\n",
        "\n",
        "trainModel(autoencoder, \n",
        "           train_data=train_dataset, \n",
        "           valid_data=val_dataset, \n",
        "           batch_size=32, \n",
        "           num_epochs=5, \n",
        "           learning_rate=0.0001,\n",
        "           model_forward=autoencoder.forwardRGB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJMn7t4DAuVP",
        "outputId": "2525f516-44ce-4419-97e1-81e4d5a05efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 4096, 1, 1])\n"
          ]
        }
      ]
    }
  ]
}